{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "BERTText.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHDmhgJtihfi"
      },
      "source": [
        "!pip install texthero\n",
        "!pip install tensorflow_addons\n",
        "!pip install tensorflow_hub\n",
        "!pip install tensorflow_text\n",
        "!pip install spacy==3.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD_ag5yYhjoL"
      },
      "source": [
        "# **BERT Text Classification - Binary Class**\n",
        "\n",
        "> [**SMS Spam Collection Dataset**](https://www.kaggle.com/uciml/sms-spam-collection-dataset) - Collection of SMS messages tagged as spam or legitimate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1qfrZ55g75X",
        "outputId": "e8242e16-c29c-4e29-f34b-e7b1acf455a5"
      },
      "source": [
        "# Import Library.\n",
        "import os, sys, warnings, logging\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.basicConfig(level=logging.WARN)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "import pandas as pd\n",
        "import texthero as hero\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow_addons.metrics import CohenKappa\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "\n",
        "# Import the BERT model.\n",
        "bert_preprocess = hub.KerasLayer(\n",
        "    \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
        ")\n",
        "bert_encoder = hub.KerasLayer(\n",
        "    \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n",
        ")\n",
        "\n",
        "# Model Configuration.\n",
        "BATCH_SIZE = 64\n",
        "NO_EPOCHS = 10\n",
        "NO_CLASSES = 2\n",
        "VALIDATION_SPLIT = 0.2\n",
        "VERBOSITY = 1\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=4, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=4, min_lr=0.00001, verbose=1),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"spamClassifier.h5\", verbose=1, save_best_only=True),\n",
        "]\n",
        "\n",
        "# Model Architecture/Pipeline.\n",
        "def create_model():\n",
        "    # Pretrained BERT model.\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
        "    preprocessed_text = bert_preprocess(text_input)\n",
        "    outputs = bert_encoder(preprocessed_text)\n",
        "    # Fine-Tuning BERT Model.\n",
        "    ml = tf.keras.layers.Dropout(0.25)(outputs[\"pooled_output\"])\n",
        "    ml = tf.keras.layers.BatchNormalization()(ml)\n",
        "    ml = tf.keras.layers.Dense(units=100, activation=\"relu\")(ml)\n",
        "    ml = tf.keras.layers.Dropout(0.25)(ml)\n",
        "    ml = tf.keras.layers.BatchNormalization()(ml)\n",
        "    ml = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")(ml)\n",
        "    # Final Model Construction.\n",
        "    model = tf.keras.Model(inputs=[text_input], outputs=[ml])\n",
        "    # Compile the Model.\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\", CohenKappa(num_classes=NO_CLASSES)],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Extract the Dataset.\n",
        "    try:\n",
        "        data = pd.read_csv(\"spam.csv\", encoding=\"ISO-8859-1\")\n",
        "    except Exception as e:\n",
        "        logger.exception(\n",
        "            \"Unable to download training CSV, check your internet connection. Error: %s\", e\n",
        "        )\n",
        "\n",
        "    # Text Cleaning and Preprocessing.\n",
        "    data[\"sms\"] = data[\"v2\"].pipe(hero.clean).pipe(hero.remove_urls)\n",
        "    data[\"class\"] = data[\"v1\"].apply(lambda x: 1 if x == \"spam\" else 0)\n",
        "\n",
        "    # Split Dataset into Training and Test Set.\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        data[\"sms\"], data[\"class\"], test_size=0.2, random_state=1, stratify=data[\"class\"],\n",
        "    )\n",
        "\n",
        "    # Call the Model Architecture.\n",
        "    model = create_model()\n",
        "\n",
        "    # Build the Model.\n",
        "    model.build(X_train.shape)\n",
        "    model.summary()\n",
        "\n",
        "    # Fit the Model.\n",
        "    model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=NO_EPOCHS,\n",
        "        verbose=VERBOSITY,\n",
        "        validation_split=VALIDATION_SPLIT,\n",
        "        callbacks=my_callbacks,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " keras_layer_2 (KerasLayer)     {'input_type_ids':   0           ['input_1[0][0]']                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " keras_layer_3 (KerasLayer)     {'encoder_outputs':  109482241   ['keras_layer_2[0][0]',          \n",
            "                                 [(None, 128, 768),               'keras_layer_2[0][1]',          \n",
            "                                 (None, 128, 768),                'keras_layer_2[0][2]']          \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 'default': (None,                                                \n",
            "                                768),                                                             \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768)}                                                       \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 768)          0           ['keras_layer_3[0][13]']         \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 768)         3072        ['dropout[0][0]']                \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 100)          76900       ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 100)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 100)         400         ['dropout_1[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            101         ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,562,714\n",
            "Trainable params: 78,737\n",
            "Non-trainable params: 109,483,977\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.5474 - accuracy: 0.7539 - cohen_kappa: 0.3471 \n",
            "Epoch 1: val_loss improved from inf to 0.36595, saving model to spamClassifier.h5\n",
            "70/70 [==============================] - 2440s 35s/step - loss: 0.5474 - accuracy: 0.7539 - cohen_kappa: 0.3471 - val_loss: 0.3660 - val_accuracy: 0.8717 - val_cohen_kappa: 0.0678 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.3083 - accuracy: 0.9020 - cohen_kappa: 0.6390 \n",
            "Epoch 2: val_loss improved from 0.36595 to 0.29543, saving model to spamClassifier.h5\n",
            "70/70 [==============================] - 2377s 34s/step - loss: 0.3083 - accuracy: 0.9020 - cohen_kappa: 0.6390 - val_loss: 0.2954 - val_accuracy: 0.8825 - val_cohen_kappa: 0.1923 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.2317 - accuracy: 0.9273 - cohen_kappa: 0.6974 \n",
            "Epoch 3: val_loss improved from 0.29543 to 0.22261, saving model to spamClassifier.h5\n",
            "70/70 [==============================] - 2342s 33s/step - loss: 0.2317 - accuracy: 0.9273 - cohen_kappa: 0.6974 - val_loss: 0.2226 - val_accuracy: 0.9031 - val_cohen_kappa: 0.4159 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.1927 - accuracy: 0.9379 - cohen_kappa: 0.7289 \n",
            "Epoch 4: val_loss improved from 0.22261 to 0.15330, saving model to spamClassifier.h5\n",
            "70/70 [==============================] - 2354s 34s/step - loss: 0.1927 - accuracy: 0.9379 - cohen_kappa: 0.7289 - val_loss: 0.1533 - val_accuracy: 0.9426 - val_cohen_kappa: 0.7167 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.1668 - accuracy: 0.9412 - cohen_kappa: 0.7411 \n",
            "Epoch 5: val_loss improved from 0.15330 to 0.14235, saving model to spamClassifier.h5\n",
            "70/70 [==============================] - 2325s 33s/step - loss: 0.1668 - accuracy: 0.9412 - cohen_kappa: 0.7411 - val_loss: 0.1424 - val_accuracy: 0.9372 - val_cohen_kappa: 0.6819 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.1614 - accuracy: 0.9437 - cohen_kappa: 0.7497 \n",
            "Epoch 6: val_loss improved from 0.14235 to 0.11947, saving model to spamClassifier.h5\n",
            "70/70 [==============================] - 2346s 34s/step - loss: 0.1614 - accuracy: 0.9437 - cohen_kappa: 0.7497 - val_loss: 0.1195 - val_accuracy: 0.9552 - val_cohen_kappa: 0.7896 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.1638 - accuracy: 0.9439 - cohen_kappa: 0.7479 \n",
            "Epoch 7: val_loss improved from 0.11947 to 0.11667, saving model to spamClassifier.h5\n",
            "70/70 [==============================] - 2346s 34s/step - loss: 0.1638 - accuracy: 0.9439 - cohen_kappa: 0.7479 - val_loss: 0.1167 - val_accuracy: 0.9605 - val_cohen_kappa: 0.8204 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.1608 - accuracy: 0.9432 - cohen_kappa: 0.7447 \n",
            "Epoch 8: val_loss improved from 0.11667 to 0.11170, saving model to spamClassifier.h5\n",
            "70/70 [==============================] - 2333s 33s/step - loss: 0.1608 - accuracy: 0.9432 - cohen_kappa: 0.7447 - val_loss: 0.1117 - val_accuracy: 0.9632 - val_cohen_kappa: 0.8331 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.1483 - accuracy: 0.9468 - cohen_kappa: 0.7619 \n",
            "Epoch 9: val_loss improved from 0.11170 to 0.11162, saving model to spamClassifier.h5\n",
            "70/70 [==============================] - 2319s 33s/step - loss: 0.1483 - accuracy: 0.9468 - cohen_kappa: 0.7619 - val_loss: 0.1116 - val_accuracy: 0.9587 - val_cohen_kappa: 0.8100 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.1409 - accuracy: 0.9506 - cohen_kappa: 0.7772 \n",
            "Epoch 10: val_loss improved from 0.11162 to 0.10936, saving model to spamClassifier.h5\n",
            "70/70 [==============================] - 2312s 33s/step - loss: 0.1409 - accuracy: 0.9506 - cohen_kappa: 0.7772 - val_loss: 0.1094 - val_accuracy: 0.9641 - val_cohen_kappa: 0.8377 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuhLdVExiza5",
        "outputId": "a3b3b4bb-82e6-43e6-de67-93a31b5f2a3b"
      },
      "source": [
        "# Load Model.\n",
        "spam_model = tf.keras.models.load_model(\n",
        "    \"spamClassifier.h5\", custom_objects={\"KerasLayer\": hub.KerasLayer}\n",
        ")\n",
        "\n",
        "reviews = [\n",
        "    \"Reply to win £100 weekly! Where will the 2022 FIFA World Cup going to be held? Send STOP to 87239 to end service.\",\n",
        "    \"Your account password has expired. Please reset your account password to continue the service.\",\n",
        "    \"You are awarded a brand new iPhone 13! Please call 09061221061 on your Mobile. Delivery within 28days. T Cs Box177. M221BP. 2yr warranty. 150ppm. 16. p pÂ£3.99\",\n",
        "    \"Your 500 free text messages are valid until 31 December 2021. Please call customer care for more details.\",\n",
        "    \"Hey Rocky, I have 2 free tickets for tomorrow's cricket game. So are you going to come with me?\",\n",
        "    \"Why don't you wait 'til at least Wednesday to see if you get your credit card?\",\n",
        "    \"Your Bank account has been compromised. You must update it immediately or your account will get closed. Click HERE to update your account.\",\n",
        "    \"Your salary of Rs. 30,000 has been credited to your bank account XXXXX4095.\",\n",
        "    \"£50 Gift Card for Amazon! Complete our Quick Survey to see if you qualify £50 Gift Card for Amazon. Click HERE to get started.\",\n",
        "]\n",
        "\n",
        "spam_model.predict(reviews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 5s 5s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9417401 ],\n",
              "       [0.7171347 ],\n",
              "       [0.9891326 ],\n",
              "       [0.88464123],\n",
              "       [0.11771929],\n",
              "       [0.02290148],\n",
              "       [0.85963535],\n",
              "       [0.64502424],\n",
              "       [0.9430161 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QpvBXetA7gyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multi-Class Classification using BERT Model.**\n",
        "\n",
        "> [**Kaggle Dataset**](https://www.kaggle.com/datasets/balatmak/newsgroup20bbcnews) - newsgroup20-bbc-news"
      ],
      "metadata": {
        "id": "XkDyFTKTgPZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Library.\n",
        "import os, sys, warnings, logging\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.basicConfig(level=logging.WARN)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import texthero as hero\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow_addons.metrics import CohenKappa\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "\n",
        "# Import the BERT model.\n",
        "bert_preprocess = hub.KerasLayer(\n",
        "    \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
        ")\n",
        "bert_encoder = hub.KerasLayer(\n",
        "    \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n",
        ")\n",
        "\n",
        "# Model Configuration.\n",
        "EPOCHS = 20\n",
        "NO_CLASSES = 5\n",
        "BATCH_SIZE = 8\n",
        "VALIDATION_SPLIT = 0.2\n",
        "VERBOSITY = 1\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=5, verbose=1),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"news_category.h5\", verbose=1, save_best_only=True),\n",
        "]\n",
        "\n",
        "# Model Architecture/Pipeline.\n",
        "def create_model():\n",
        "    # Pretrained BERT model.\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"text\")\n",
        "    preprocessed_text = bert_preprocess(text_input)\n",
        "    outputs = bert_encoder(preprocessed_text)\n",
        "    # Fine-Tuning BERT Model.\n",
        "    out = tf.keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=\"l2\")(outputs[\"pooled_output\"])\n",
        "    out = tf.keras.layers.Dropout(0.4)(out)\n",
        "    out = tf.keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=\"l2\")(out)\n",
        "    out = tf.keras.layers.Dropout(0.4)(out)\n",
        "    out = tf.keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=\"l2\")(out)\n",
        "    out = tf.keras.layers.Dropout(0.4)(out)\n",
        "    out = tf.keras.layers.Dense(NO_CLASSES, activation=\"softmax\")(out)\n",
        "    # Final Model Construction.\n",
        "    model = tf.keras.Model(inputs=[text_input], outputs=[out])\n",
        "    # Compile the Model.\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"AUC\", CohenKappa(num_classes=NO_CLASSES)],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Extract the Dataset.\n",
        "    try:\n",
        "        data = pd.read_csv(\n",
        "            \"https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv\"\n",
        "        )\n",
        "        print(data.head())\n",
        "    except Exception as e:\n",
        "        logger.exception(\n",
        "            \"Unable to download training CSV, check your internet connection. Error: %s\", e\n",
        "        )\n",
        "\n",
        "    print(\"\\nShape of the dataset is\", data.shape, \"\\n\")\n",
        "\n",
        "    print(\"Class Frequency: \\n\", data[\"category\"].value_counts(), \"\\n\")\n",
        "\n",
        "    # Text Preprocessing and Encode Categorical Column.\n",
        "    data[\"text\"] = data[\"text\"].pipe(hero.clean).pipe(hero.remove_urls)\n",
        "    data[\"category\"] = data[\"category\"].map(\n",
        "        {\"sport\": 0, \"business\": 1, \"politics\": 2, \"tech\": 3, \"entertainment\": 4}\n",
        "    )\n",
        "    y = tf.keras.utils.to_categorical(data[\"category\"].values, num_classes=NO_CLASSES)\n",
        "\n",
        "    # Split Dataset into Training and Test Set.\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        data[\"text\"], y, test_size=0.2, random_state=1, stratify=y\n",
        "    )\n",
        "\n",
        "    # Call the Model Architecture.\n",
        "    model = create_model()\n",
        "\n",
        "    # Build the Model.\n",
        "    model.build(X_train.shape)\n",
        "    model.summary()\n",
        "\n",
        "    # Fit the Model.\n",
        "    model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=NO_EPOCHS,\n",
        "        verbose=VERBOSITY,\n",
        "        validation_split=VALIDATION_SPLIT,\n",
        "        callbacks=my_callbacks,\n",
        "    )"
      ],
      "metadata": {
        "id": "aUgX-UJ22zjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af01f0f6-df41-4bbe-b2b2-30f780be409c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        category                                               text\n",
            "0           tech  tv future in the hands of viewers with home th...\n",
            "1       business  worldcom boss  left books alone  former worldc...\n",
            "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
            "3          sport  yeading face newcastle in fa cup premiership s...\n",
            "4  entertainment  ocean s twelve raids box office ocean s twelve...\n",
            "\n",
            "Shape of the dataset is (2225, 2) \n",
            "\n",
            "Class Frequency: \n",
            " sport            511\n",
            "business         510\n",
            "politics         417\n",
            "tech             401\n",
            "entertainment    386\n",
            "Name: category, dtype: int64 \n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " keras_layer_4 (KerasLayer)     {'input_mask': (Non  0           ['text[0][0]']                   \n",
            "                                e, 128),                                                          \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " keras_layer_5 (KerasLayer)     {'default': (None,   109482241   ['keras_layer_4[0][0]',          \n",
            "                                768),                             'keras_layer_4[0][1]',          \n",
            "                                 'encoder_outputs':               'keras_layer_4[0][2]']          \n",
            "                                 [(None, 128, 768),                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768),                                                       \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 768)}                                                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 256)          196864      ['keras_layer_5[0][13]']         \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 256)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 128)          32896       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 128)          0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 128)          16512       ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 128)          0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 5)            645         ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,729,158\n",
            "Trainable params: 246,917\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "223/223 [==============================] - ETA: 0s - loss: 4.3146 - auc: 0.5838 - cohen_kappa: 0.0761\n",
            "Epoch 1: val_loss improved from inf to 2.65630, saving model to news_category.h5\n",
            "223/223 [==============================] - 1012s 4s/step - loss: 4.3146 - auc: 0.5838 - cohen_kappa: 0.0761 - val_loss: 2.6563 - val_auc: 0.6928 - val_cohen_kappa: 0.1129 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "223/223 [==============================] - ETA: 0s - loss: 2.1710 - auc: 0.7453 - cohen_kappa: 0.2156\n",
            "Epoch 2: val_loss improved from 2.65630 to 1.68718, saving model to news_category.h5\n",
            "223/223 [==============================] - 1041s 5s/step - loss: 2.1710 - auc: 0.7453 - cohen_kappa: 0.2156 - val_loss: 1.6872 - val_auc: 0.8341 - val_cohen_kappa: 0.2977 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "223/223 [==============================] - ETA: 0s - loss: 1.6742 - auc: 0.7952 - cohen_kappa: 0.2833\n",
            "Epoch 3: val_loss improved from 1.68718 to 1.42952, saving model to news_category.h5\n",
            "223/223 [==============================] - 1022s 5s/step - loss: 1.6742 - auc: 0.7952 - cohen_kappa: 0.2833 - val_loss: 1.4295 - val_auc: 0.8469 - val_cohen_kappa: 0.3391 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "223/223 [==============================] - ETA: 0s - loss: 1.4512 - auc: 0.8226 - cohen_kappa: 0.3335\n",
            "Epoch 4: val_loss improved from 1.42952 to 1.27667, saving model to news_category.h5\n",
            "223/223 [==============================] - 1024s 5s/step - loss: 1.4512 - auc: 0.8226 - cohen_kappa: 0.3335 - val_loss: 1.2767 - val_auc: 0.8892 - val_cohen_kappa: 0.4849 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "223/223 [==============================] - ETA: 0s - loss: 1.3770 - auc: 0.8286 - cohen_kappa: 0.3577\n",
            "Epoch 5: val_loss improved from 1.27667 to 1.22535, saving model to news_category.h5\n",
            "223/223 [==============================] - 1037s 5s/step - loss: 1.3770 - auc: 0.8286 - cohen_kappa: 0.3577 - val_loss: 1.2254 - val_auc: 0.8737 - val_cohen_kappa: 0.3800 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "223/223 [==============================] - ETA: 0s - loss: 1.3336 - auc: 0.8316 - cohen_kappa: 0.3562\n",
            "Epoch 6: val_loss improved from 1.22535 to 1.22365, saving model to news_category.h5\n",
            "223/223 [==============================] - 1035s 5s/step - loss: 1.3336 - auc: 0.8316 - cohen_kappa: 0.3562 - val_loss: 1.2237 - val_auc: 0.8714 - val_cohen_kappa: 0.3616 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "223/223 [==============================] - ETA: 0s - loss: 1.3485 - auc: 0.8242 - cohen_kappa: 0.3493\n",
            "Epoch 7: val_loss did not improve from 1.22365\n",
            "223/223 [==============================] - 1017s 5s/step - loss: 1.3485 - auc: 0.8242 - cohen_kappa: 0.3493 - val_loss: 1.2551 - val_auc: 0.8688 - val_cohen_kappa: 0.4998 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "223/223 [==============================] - ETA: 0s - loss: 1.2861 - auc: 0.8384 - cohen_kappa: 0.3859\n",
            "Epoch 8: val_loss did not improve from 1.22365\n",
            "223/223 [==============================] - 1011s 5s/step - loss: 1.2861 - auc: 0.8384 - cohen_kappa: 0.3859 - val_loss: 1.3021 - val_auc: 0.8361 - val_cohen_kappa: 0.3949 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "223/223 [==============================] - ETA: 0s - loss: 1.2431 - auc: 0.8490 - cohen_kappa: 0.4137\n",
            "Epoch 9: val_loss improved from 1.22365 to 1.13231, saving model to news_category.h5\n",
            "223/223 [==============================] - 1018s 5s/step - loss: 1.2431 - auc: 0.8490 - cohen_kappa: 0.4137 - val_loss: 1.1323 - val_auc: 0.9026 - val_cohen_kappa: 0.5621 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "223/223 [==============================] - ETA: 0s - loss: 1.2412 - auc: 0.8473 - cohen_kappa: 0.4229\n",
            "Epoch 10: val_loss improved from 1.13231 to 1.05245, saving model to news_category.h5\n",
            "223/223 [==============================] - 1017s 5s/step - loss: 1.2412 - auc: 0.8473 - cohen_kappa: 0.4229 - val_loss: 1.0524 - val_auc: 0.9181 - val_cohen_kappa: 0.5858 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model.\n",
        "news_category = tf.keras.models.load_model(\n",
        "    \"news_category.h5\", custom_objects={\"KerasLayer\": hub.KerasLayer}\n",
        ")\n",
        "\n",
        "\n",
        "def predict_class(reviews):\n",
        "    \"\"\"Predict Class of Input Text.\"\"\"\n",
        "    import numpy as np\n",
        "\n",
        "    return [np.argmax(pred) for pred in news_category.predict(reviews)]\n",
        "\n",
        "\n",
        "# Predict Result.\n",
        "reviews = [\n",
        "    \"iPhone Users Alert! THIS Apple iPhone could cost less than Rs 20,000.\",\n",
        "    \"Russia-Ukraine conflict: After a 'genius' remark, Donald Trump says Putin playing Biden like a drum.\",\n",
        "    \"Czech Republic join Poland, Sweden in refusing to play Russia in 2022 World Cup playoffs.\",\n",
        "    \"Housebuilders must ‘go further’ in remediation pledge.\",\n",
        "    \"CODA lands top SAG award on road to the Oscars and more.\",\n",
        "]\n",
        "\n",
        "predict_class(reviews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdgBYdDBIPeB",
        "outputId": "fe55dfdb-5d8b-4d96-a536-ceeeac4b54a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 1, 2, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lAC7aDJ9EAdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoSzXSFa3mg4"
      },
      "source": [
        "# **Multi-label Classification using BERT Model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cnf7gDVCwmSV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "da139638-1c7a-4429-8788-1e5f39ecf5d2"
      },
      "source": [
        "# Import Library.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import texthero as hero\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow_addons.metrics import CohenKappa\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "\n",
        "# Import the BERT model.\n",
        "bert_preprocess = hub.KerasLayer(\n",
        "    \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
        ")\n",
        "bert_encoder = hub.KerasLayer(\n",
        "    \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n",
        ")\n",
        "\n",
        "# Load Dataset.\n",
        "data = pd.read_csv(\"so_dataset_2_tags.csv\")\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title                 tags  \\\n",
              "0  Flask-SQLAlchemy - When are the tables/databas...  ['python', 'mysql']   \n",
              "1        Combining two PHP variables for MySQL query     ['php', 'mysql']   \n",
              "2  'Counting' the number of records that match a ...     ['php', 'mysql']   \n",
              "3  Insert new row in a table and auto id number. ...     ['php', 'mysql']   \n",
              "4             Create Multiple MySQL tables using PHP     ['php', 'mysql']   \n",
              "\n",
              "   mysql  python  php  \n",
              "0      1     1.0  0.0  \n",
              "1      1     0.0  1.0  \n",
              "2      1     0.0  1.0  \n",
              "3      1     0.0  1.0  \n",
              "4      1     0.0  1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e71bba02-561e-4383-be42-6b5c1d487777\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>tags</th>\n",
              "      <th>mysql</th>\n",
              "      <th>python</th>\n",
              "      <th>php</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Flask-SQLAlchemy - When are the tables/databas...</td>\n",
              "      <td>['python', 'mysql']</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Combining two PHP variables for MySQL query</td>\n",
              "      <td>['php', 'mysql']</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'Counting' the number of records that match a ...</td>\n",
              "      <td>['php', 'mysql']</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Insert new row in a table and auto id number. ...</td>\n",
              "      <td>['php', 'mysql']</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Create Multiple MySQL tables using PHP</td>\n",
              "      <td>['php', 'mysql']</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e71bba02-561e-4383-be42-6b5c1d487777')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e71bba02-561e-4383-be42-6b5c1d487777 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e71bba02-561e-4383-be42-6b5c1d487777');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7iakkqWxCMS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "601c9ed1-3182-42b6-92bd-ee689e1369b3"
      },
      "source": [
        "# Making the Tags in the form: ['item1', 'item2', ..., 'itemN']\n",
        "data[\"tags\"] = data[\"tags\"].apply(lambda x: ast.literal_eval(x))\n",
        "\n",
        "# Convert \"mysql\" column to float datatype.\n",
        "data[\"mysql\"] = data[\"mysql\"].astype(float)\n",
        "\n",
        "# Text Cleaning and Preprocessing.\n",
        "data[\"title\"] = data[\"title\"].pipe(hero.clean).pipe(hero.remove_urls)\n",
        "\n",
        "# Split Dataset into Dependent and Independent Features.\n",
        "X = data[\"title\"]\n",
        "y = data[[\"mysql\", \"python\", \"php\"]]\n",
        "\n",
        "# Split Dataset into Training and Test Set.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.1, random_state=1, stratify=y\n",
        ")\n",
        "\n",
        "# Model Configuration.\n",
        "BATCH_SIZE = 64\n",
        "NO_EPOCHS = 20\n",
        "NO_CLASSES = y.shape[1]\n",
        "VALIDATION_SPLIT = 0.2\n",
        "VERBOSITY = 1\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=5, verbose=1),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"tagsClassify.h5\", verbose=1, save_best_only=True),\n",
        "]\n",
        "\n",
        "# Model Architecture/Pipeline.\n",
        "def create_model():\n",
        "    # Pretrained BERT model.\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
        "    preprocessed_text = bert_preprocess(text_input)\n",
        "    outputs = bert_encoder(preprocessed_text)\n",
        "    # Fine-Tuning BERT Model.\n",
        "    ml = tf.keras.layers.Dropout(0.25)(outputs[\"pooled_output\"])\n",
        "    ml = tf.keras.layers.BatchNormalization()(ml)\n",
        "    ml = tf.keras.layers.Dense(units=100, activation=\"relu\")(ml)\n",
        "    ml = tf.keras.layers.Dropout(0.25)(ml)\n",
        "    ml = tf.keras.layers.BatchNormalization()(ml)\n",
        "    ml = tf.keras.layers.Dense(units=NO_CLASSES, activation=\"sigmoid\")(ml)\n",
        "    # Final Model Construction.\n",
        "    model = tf.keras.Model(inputs=[text_input], outputs=[ml])\n",
        "    # Compile the Model.\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\", CohenKappa(num_classes=NO_CLASSES)],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "# Call the Model Architecture.\n",
        "model = create_model()\n",
        "\n",
        "# Build the Model.\n",
        "model.build(X_train.shape)\n",
        "model.summary()\n",
        "\n",
        "# Fit the Model.\n",
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=NO_EPOCHS,\n",
        "    verbose=VERBOSITY,\n",
        "    validation_split=VALIDATION_SPLIT,\n",
        "    callbacks=my_callbacks,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " keras_layer_6 (KerasLayer)     {'input_type_ids':   0           ['input_2[0][0]']                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " keras_layer_7 (KerasLayer)     {'sequence_output':  109482241   ['keras_layer_6[0][0]',          \n",
            "                                 (None, 128, 768),                'keras_layer_6[0][1]',          \n",
            "                                 'default': (None,                'keras_layer_6[0][2]']          \n",
            "                                768),                                                             \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 128, 768),                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768)}                                                       \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 768)          0           ['keras_layer_7[0][13]']         \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 768)         3072        ['dropout_5[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 100)          76900       ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 100)          0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 100)         400         ['dropout_6[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 3)            303         ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,562,916\n",
            "Trainable params: 78,939\n",
            "Non-trainable params: 109,483,977\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.8755 - accuracy: 0.3178 - cohen_kappa: 0.0000e+00 \n",
            "Epoch 1: val_loss improved from inf to 0.86745, saving model to tagsClassify.h5\n",
            "3/3 [==============================] - 80s 19s/step - loss: 0.8755 - accuracy: 0.3178 - cohen_kappa: 0.0000e+00 - val_loss: 0.8674 - val_accuracy: 0.0000e+00 - val_cohen_kappa: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.8270 - accuracy: 0.2791 - cohen_kappa: 0.0000e+00 \n",
            "Epoch 2: val_loss improved from 0.86745 to 0.82203, saving model to tagsClassify.h5\n",
            "3/3 [==============================] - 66s 19s/step - loss: 0.8270 - accuracy: 0.2791 - cohen_kappa: 0.0000e+00 - val_loss: 0.8220 - val_accuracy: 0.0000e+00 - val_cohen_kappa: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.8530 - accuracy: 0.2713 - cohen_kappa: 0.0000e+00 \n",
            "Epoch 3: val_loss improved from 0.82203 to 0.73882, saving model to tagsClassify.h5\n",
            "3/3 [==============================] - 66s 19s/step - loss: 0.8530 - accuracy: 0.2713 - cohen_kappa: 0.0000e+00 - val_loss: 0.7388 - val_accuracy: 0.0000e+00 - val_cohen_kappa: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.8180 - accuracy: 0.2713 - cohen_kappa: 0.0000e+00 \n",
            "Epoch 4: val_loss did not improve from 0.73882\n",
            "3/3 [==============================] - 64s 18s/step - loss: 0.8180 - accuracy: 0.2713 - cohen_kappa: 0.0000e+00 - val_loss: 0.7552 - val_accuracy: 0.0000e+00 - val_cohen_kappa: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.8273 - accuracy: 0.3023 - cohen_kappa: 0.0000e+00 \n",
            "Epoch 5: val_loss did not improve from 0.73882\n",
            "3/3 [==============================] - 66s 19s/step - loss: 0.8273 - accuracy: 0.3023 - cohen_kappa: 0.0000e+00 - val_loss: 0.7779 - val_accuracy: 0.0000e+00 - val_cohen_kappa: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.7475 - accuracy: 0.3566 - cohen_kappa: 0.0000e+00 \n",
            "Epoch 6: val_loss did not improve from 0.73882\n",
            "3/3 [==============================] - 64s 18s/step - loss: 0.7475 - accuracy: 0.3566 - cohen_kappa: 0.0000e+00 - val_loss: 0.8075 - val_accuracy: 0.0000e+00 - val_cohen_kappa: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.7289 - accuracy: 0.3876 - cohen_kappa: 0.0000e+00 \n",
            "Epoch 7: val_loss did not improve from 0.73882\n",
            "3/3 [==============================] - 68s 20s/step - loss: 0.7289 - accuracy: 0.3876 - cohen_kappa: 0.0000e+00 - val_loss: 0.7957 - val_accuracy: 0.0000e+00 - val_cohen_kappa: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.7319 - accuracy: 0.3566 - cohen_kappa: 0.0000e+00 \n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.73882\n",
            "3/3 [==============================] - 64s 18s/step - loss: 0.7319 - accuracy: 0.3566 - cohen_kappa: 0.0000e+00 - val_loss: 0.7469 - val_accuracy: 0.0000e+00 - val_cohen_kappa: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 8: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f97e40a4610>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDSP-CmfyC08",
        "outputId": "d0c84017-bba5-4757-9f40-3e73ba8d197b"
      },
      "source": [
        "# Load Model.\n",
        "tagsModel = tf.keras.models.load_model(\n",
        "    \"tagsClassify.h5\", custom_objects={\"KerasLayer\": hub.KerasLayer}\n",
        ")\n",
        "\n",
        "reviews = [\n",
        "    \"How do I merge two dictionaries in a single expression (taking union of dictionaries)?\",\n",
        "    \"How to connect Python in MongoDB?\",\n",
        "    \"What are the steps to create a new database using MySQL and PHP?\",\n",
        "]\n",
        "\n",
        "tagsModel.predict(reviews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5547276 , 0.59171814, 0.5183102 ],\n",
              "       [0.45760947, 0.5581999 , 0.51863074],\n",
              "       [0.49568376, 0.5485536 , 0.5535065 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}
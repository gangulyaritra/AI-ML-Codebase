{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM & BiLSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4akUFOKqlG6"
      },
      "source": [
        "# **LSTM & Bidirectional LSTM Model**\n",
        "\n",
        "> [**Understanding LSTM Networks**](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Kaggle.\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "metadata": {
        "id": "amQ1DIFUsGhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Files Upload.\n",
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "CIeZTVjRsGnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Kaggle Folder.\n",
        "!mkdir ~/.kaggle\n",
        "\n",
        "# Copy the kaggle.json to the folder created.\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# Permission for the json file to act.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "-AsIXc8msGsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Download.\n",
        "!kaggle datasets download -d ue153011/spam-mail-detection-dataset"
      ],
      "metadata": {
        "id": "9WWfqiyVsGyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip Dataset.\n",
        "!unzip spam-mail-detection-dataset.zip"
      ],
      "metadata": {
        "id": "dV1kB1WasP1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Spam Mail Classification**\n",
        "\n",
        "> [**Kaggle - Spam Mail Detection Dataset**](https://www.kaggle.com/datasets/ue153011/spam-mail-detection-dataset)"
      ],
      "metadata": {
        "id": "u6jhX5X9-_Bx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQzNjen1BQPi"
      },
      "source": [
        "!pip install texthero\n",
        "!pip install textblob\n",
        "!pip install tensorflow_addons\n",
        "!pip install spacy==3.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moBsiw1B-QFj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bac0361-035e-4d2f-89d8-7e525c3348c8"
      },
      "source": [
        "# Import Library.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "from textblob import TextBlob, Word\n",
        "import texthero as hero\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow_addons.metrics import CohenKappa\n",
        "from tensorflow.keras.layers import (\n",
        "    Embedding,\n",
        "    LSTM,\n",
        "    Bidirectional,\n",
        "    Dense,\n",
        "    Dropout,\n",
        "    LayerNormalization,\n",
        ")\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Model Configuration.\n",
        "BATCH_SIZE = 256\n",
        "NO_EPOCHS = 50\n",
        "NO_CLASSES = 2\n",
        "VALIDATION_SPLIT = 0.2\n",
        "VERBOSITY = 1\n",
        "VOC_SIZE = 10000\n",
        "MAX_LEN = 20\n",
        "my_callbacks = [\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=25, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "# Read Dataset.\n",
        "data = pd.read_csv(\"spam_mail_data.csv\")\n",
        "\n",
        "# Text Cleaning and Preprocessing.\n",
        "data[\"Message\"] = data[\"Message\"].pipe(hero.clean).pipe(hero.remove_urls)\n",
        "data[\"Message\"] = data[\"Message\"].apply(\n",
        "    lambda x: \" \".join([Word(word).lemmatize() for word in x.split()])\n",
        ")\n",
        "data[\"Message\"] = data[\"Message\"].apply(lambda x: str(TextBlob(x).correct()))\n",
        "data[\"Class\"] = data[\"Category\"].apply(lambda x: 1 if x == \"spam\" else 0)\n",
        "\n",
        "# Split Dataset into Dependent and Independent Features.\n",
        "X = data[\"Message\"]\n",
        "y = data[\"Class\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axMrudycIJI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0208f6d4-f9b3-4c9e-ec7a-22c6e8b4971c"
      },
      "source": [
        "# One Hot Representation.\n",
        "onehot_repr = [one_hot(words, VOC_SIZE) for words in X]\n",
        "\n",
        "embedded_docs = pad_sequences(onehot_repr, padding=\"post\", maxlen=MAX_LEN)\n",
        "print(embedded_docs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1900 1992 9225 ...    0    0    0]\n",
            " [2728 3232   39 ...    0    0    0]\n",
            " [3929 6969 7004 ... 9357 9019 9766]\n",
            " ...\n",
            " [9097 8222 4799 ...    0    0    0]\n",
            " [2898 5199 3088 ...    0    0    0]\n",
            " [9769 2879 1503 ...    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ivzrWWvxS5R"
      },
      "source": [
        "# Split Dataset into Training and Test Set.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    np.array(embedded_docs), y, test_size=0.25, random_state=1, stratify=y\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfzKh_5IBWzt"
      },
      "source": [
        "def Simple_LSTM():\n",
        "    model = Sequential()\n",
        "    model.add(\n",
        "        Embedding(input_dim=VOC_SIZE, output_dim=64, input_length=MAX_LEN)\n",
        "    )  # Embedding Layer.\n",
        "    model.add(LSTM(100))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(Dense(units=1, activation=\"sigmoid\"))\n",
        "    # Compile the Model.\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\", CohenKappa(num_classes=NO_CLASSES)],\n",
        "    )\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JKpO5jCCJEW"
      },
      "source": [
        "def Bidirectional_LSTM():\n",
        "    model = Sequential()\n",
        "    model.add(\n",
        "        Embedding(input_dim=VOC_SIZE, output_dim=64, input_length=MAX_LEN)\n",
        "    )  # Embedding Layer.\n",
        "    model.add(Bidirectional(LSTM(100)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(Dense(units=1, activation=\"sigmoid\"))\n",
        "    # Compile the Model.\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\", CohenKappa(num_classes=NO_CLASSES)],\n",
        "    )\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74Kpq5kWCPSN"
      },
      "source": [
        "# Cost Sensitive Learning.\n",
        "weights_assigned = {0: 1, 1: 7}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly7ALV8vxPNq"
      },
      "source": [
        "## **Train & Evaluate the LSTM Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT8f2aATCP2s"
      },
      "source": [
        "# Call the LSTM Model Architecture.\n",
        "lstm_model = Simple_LSTM()\n",
        "\n",
        "# Build the Model.\n",
        "lstm_model.build(X_train.shape)\n",
        "lstm_model.summary()\n",
        "\n",
        "# Fit the Model.\n",
        "lstm_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    class_weight=weights_assigned,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=NO_EPOCHS,\n",
        "    verbose=VERBOSITY,\n",
        "    validation_split=VALIDATION_SPLIT,\n",
        "    callbacks=my_callbacks,\n",
        ")\n",
        "\n",
        "# Model Evaluation.\n",
        "print(\"\\n Model Evaluation: \", lstm_model.evaluate(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj8Lvfw6CisY",
        "outputId": "a129c516-1ece-4d67-8ad5-4782de92ccf0"
      },
      "source": [
        "# Performance Metrics and Accuracy.\n",
        "y_pred = lstm_model.predict(X_test)\n",
        "print(\"ROC-AUC Score is \", roc_auc_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score is  0.9940138877803496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfB_yLVZzSN9"
      },
      "source": [
        "## **Train & Evaluate the Bidirectional LSTM Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA3d9W5DCU50"
      },
      "source": [
        "# Call the Bidirectional LSTM Model Architecture.\n",
        "bi_lstm = Bidirectional_LSTM()\n",
        "\n",
        "# Build the Model.\n",
        "bi_lstm.build(X_train.shape)\n",
        "bi_lstm.summary()\n",
        "\n",
        "# Fit the Model.\n",
        "bi_lstm.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    class_weight=weights_assigned,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=NO_EPOCHS,\n",
        "    verbose=VERBOSITY,\n",
        "    validation_split=VALIDATION_SPLIT,\n",
        "    callbacks=my_callbacks,\n",
        ")\n",
        "\n",
        "# Model Evaluation.\n",
        "print(\"\\n Model Evaluation: \", bi_lstm.evaluate(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR_DG63fC5n9",
        "outputId": "07b9a57f-d866-4f9d-c509-bc7ec001d82c"
      },
      "source": [
        "# Performance Metrics and Accuracy.\n",
        "y_pred = bi_lstm.predict(X_test)\n",
        "print(\"ROC-AUC Score is \", roc_auc_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score is  0.989606335523807\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cross-Validation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e0ftWsxdT3H"
      },
      "source": [
        "# **Cross-Validation Techniques**\n",
        "\n",
        ">  [**Cross-Validation: Evaluating Estimator Performance**](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)\n",
        "\n",
        ">  [**sklearn.model_selection: Model Selection**](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection)\n",
        "\n",
        "Cross-validation is a resampling procedure used to evaluate machine learning models and verify how the model will perform for an independent test dataset.\n",
        "\n",
        "**Why Cross Validation is Important?**\n",
        "\n",
        "We often randomly split the dataset into training and validation sets to develop a machine learning model. The training data is used to train the ML model, and the same model is tested on independent validation data to evaluate the performance of the model.\n",
        "\n",
        "With the change in the `random_state` of the split, the accuracy of the model also changes, so we are unable to achieve a fixed accuracy for the model. The testing data should be kept independent of the training data so that no data leakage occurs. During the development of an ML model using the training data, the model performance needs to be evaluated. Here's the importance of cross-validation comes into the picture.\n",
        "\n",
        "**Data needs to be split into:**\n",
        "\n",
        "*   **Training Data:** Use for model development.\n",
        "*   **Validation Data:** Use for validating the performance of the same model.\n",
        "\n",
        "![CV.png](https://www.upgrad.com/blog/wp-content/uploads/2020/01/data-preprocessing-machine-learning-5.png)\n",
        "\n",
        "In simple terms, cross-validation allows utilizing the data even better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwWlOe_LT4jL"
      },
      "source": [
        "# Import Library.\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> [**Kaggle Dataset**](https://www.kaggle.com/mathchi/diabetes-data-set)"
      ],
      "metadata": {
        "id": "STCcETYqGh4x"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vgSP1FwqVSS4",
        "outputId": "fa0e9b85-8de7-4a99-ef74-2e7d7b60631d"
      },
      "source": [
        "# Load Dataset.\n",
        "data = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/plotly/datasets/master/diabetes.csv\"\n",
        ")\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-573b2d83-fdf8-43e9-b37c-1bddf48d5b4b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-573b2d83-fdf8-43e9-b37c-1bddf48d5b4b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-573b2d83-fdf8-43e9-b37c-1bddf48d5b4b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-573b2d83-fdf8-43e9-b37c-1bddf48d5b4b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJOA1JOMV2Id",
        "outputId": "0067cdae-70e6-4a91-dd9d-6b4600620d0a"
      },
      "source": [
        "# Dataset Summary.\n",
        "data.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 768 entries, 0 to 767\n",
            "Data columns (total 9 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Pregnancies               768 non-null    int64  \n",
            " 1   Glucose                   768 non-null    int64  \n",
            " 2   BloodPressure             768 non-null    int64  \n",
            " 3   SkinThickness             768 non-null    int64  \n",
            " 4   Insulin                   768 non-null    int64  \n",
            " 5   BMI                       768 non-null    float64\n",
            " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
            " 7   Age                       768 non-null    int64  \n",
            " 8   Outcome                   768 non-null    int64  \n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 54.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5zIq_h6V20V"
      },
      "source": [
        "# Split the dataset into features and target values.\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "\n",
        "# Feature Scaling.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test set.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cc-sFvDdiSr"
      },
      "source": [
        "# **HoldOut Validation Approach - Train and Test Split.**\n",
        "\n",
        "The holdout technique is an exhaustive cross-validation method that randomly splits the dataset into train and test sets. In the case of holdout cross-validation, the dataset is randomly split into training and validation data. Generally, the split of training data is more than test data. The training data is used to induce the model, and the validation data evaluates the performance of the model. The more data is used to train the model, the better the model becomes. For the holdout cross-validation method, a good amount of data is isolated from the training set.\n",
        "\n",
        "*   Holdout Cross-Validation is not suitable for an imbalanced dataset.\n",
        "*   A lot of data is isolated from training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcj6I6m5WjL1",
        "outputId": "4e71edf3-1f89-4258-b043-96b8f961f1c8"
      },
      "source": [
        "# Decision Tree Classifier.\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "result = model.score(X_test, y_test)\n",
        "print(result)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7402597402597403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTI9iUHLXp5v"
      },
      "source": [
        "# **K-Fold Cross Validation**\n",
        "\n",
        "> [**sklearn.model_selection.KFold**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold)\n",
        "\n",
        "In $K$-fold cross-validation, the original dataset is equally partitioned into $K$ subparts or folds. Out of the $K$-folds or groups, for each iteration, one group is selected as the validation set, and the remaining $(K-1)$ groups are selected as the training set.\n",
        "\n",
        "![Kfold.gif](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4b/KfoldCV.gif/1920px-KfoldCV.gif)\n",
        "\n",
        "Illustration of $K$-fold cross-validation when $n = 12$ observations and $K = 3$. After data gets shuffled, a total of 3 models will get trained and tested. The process is repeated for $K$ times until each group is treated as validation and remaining as the training data.\n",
        "\n",
        "### **Diagram of $K$-fold cross-validation.**\n",
        "\n",
        "![KFOLD.png](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/K-fold_cross_validation_EN.svg/1920px-K-fold_cross_validation_EN.svg.png)\n",
        "\n",
        "The final accuracy of the model is computed by taking the mean accuracy of the $K$-models validation data. That is, $acc_{CV} = \\sum_{i=1}^{K}\\frac{acc_{i}}{K}$\n",
        "\n",
        "*   The model has low bias and low time complexity.\n",
        "*   The entire dataset is utilized for both training and validation.\n",
        "*   It is not suitable for an imbalanced dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k21_JGXkXuas",
        "outputId": "7503aca7-35a7-4271-8f0a-6c7b84b7f012"
      },
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "kfold_val = KFold(10)\n",
        "results = cross_val_score(model, X_train, y_train, cv=kfold_val)\n",
        "print(results)\n",
        "print(np.mean(results))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.72580645 0.77419355 0.82258065 0.72580645 0.60655738 0.80327869\n",
            " 0.63934426 0.67213115 0.7704918  0.78688525]\n",
            "0.7327075621364358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqO1UOjIZpnp"
      },
      "source": [
        "# **Stratified K-fold Cross Validation**\n",
        "\n",
        "> [**sklearn.model_selection.StratifiedKFold**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold)\n",
        "\n",
        "For all the cross-validation techniques discussed above, it may not work well with an imbalanced dataset. Stratified $K$-fold cross-validation solved the problem of an imbalanced dataset.\n",
        "\n",
        "In Stratified $K$-fold cross-validation, the dataset gets partitioned into $K$ groups or folds such that the validation data has an equal number of instances of the target class label. It ensures that one particular class is not over-present in the validation or train data, especially when the dataset is imbalanced.\n",
        "\n",
        "![SKfold.png](https://dataaspirant.com/wp-content/uploads/2020/12/8-Stratified-K-Fold-Cross-Validation.png)\n",
        "\n",
        "In Stratified $K$-fold cross-validation, each fold has equal instances of the target class. The final score is computed by taking the mean of scores of each fold. Stratified $K$-fold cross-validation works well for an imbalanced dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NARHk1QZuXd",
        "outputId": "f064bf7b-ad36-4009-f060-4e081e803684"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "skfold = StratifiedKFold(n_splits=10)\n",
        "results = cross_val_score(model, X_train, y_train, cv=skfold)\n",
        "print(results)\n",
        "print(np.mean(results))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.74193548 0.70967742 0.70967742 0.70967742 0.6557377  0.78688525\n",
            " 0.72131148 0.68852459 0.75409836 0.70491803]\n",
            "0.7182443151771549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amtudKs-mue7"
      },
      "source": [
        "# **Leave-P-Out Cross Validation (LpOCV)**\n",
        "\n",
        "> [**sklearn.model_selection.LeavePOut**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePOut.html)\n",
        "\n",
        "Leave-P-Out cross-validation ($LpOCV$) is an exhaustive cross-validation technique that involves using $p$-observation as validation data, whereas the remaining data is used to train the model. This gets repeated in all ways to cut the original sample in a validation set of $p$ observations, while the rest gets into the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_MQRr9rmuy4",
        "outputId": "b8b50ee7-ed1a-4c27-fc53-07b294ae5e82"
      },
      "source": [
        "from sklearn.model_selection import LeavePOut, cross_val_score\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "lpoCV = LeavePOut(2)\n",
        "results = cross_val_score(model, X_train, y_train, cv=lpoCV)\n",
        "print(results)\n",
        "print(np.mean(results))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.  0.5 0.5 ... 0.5 1.  0.5]\n",
            "0.7149412033519138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WReR5GS8auL1"
      },
      "source": [
        "# **Leave-One-Out Cross Validation (LOOCV)**\n",
        "\n",
        "> [**sklearn.model_selection.LeaveOneOut**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut)\n",
        "\n",
        "Leave-One-Out cross-validation ($LOOCV$) is an exhaustive cross-validation technique. It is a category of $LpOCV$ with the case of $p=1$.\n",
        "\n",
        "![LOOCV.gif](https://upload.wikimedia.org/wikipedia/commons/c/c7/LOOCV.gif)\n",
        "\n",
        "Illustration of leave-one-out cross-validation ($LOOCV$), when $n = 8$ observations. A total of 8 models get trained and tested. For a dataset having $n$ rows, the $1^{st}$ row is selected for validation, and the rest $(n-1)$ rows are used to train the model. For the next iteration, the $2^{nd}$ row is selected for validation and the rest to train the model. Similarly, the process gets repeated until $n$ steps or the desired number of operations.\n",
        "\n",
        "Both the above two cross-validation techniques (i.e., $LpOCV$ and $LOOCV$) are types of exhaustive cross-validation. Exhaustive cross-validation methods are cross-validation methods that learn and test in all possible ways.\n",
        "\n",
        "*   Simple, easy to understand, and implement.\n",
        "*   The model may lead to a low bias.\n",
        "*   The computation time required is high."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meXYXG38azbk",
        "outputId": "9f8ba850-a556-45c5-8dbc-0dddd6820124"
      },
      "source": [
        "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "looCV = LeaveOneOut()\n",
        "results = cross_val_score(model, X_train, y_train, cv=looCV)\n",
        "print(results)\n",
        "print(np.mean(results))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1.\n",
            " 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1.\n",
            " 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1.\n",
            " 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.\n",
            " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0.\n",
            " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1.\n",
            " 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0.\n",
            " 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0.\n",
            " 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
            "0.7084690553745928\n"
          ]
        }
      ]
    }
  ]
}
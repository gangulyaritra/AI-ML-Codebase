{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Scaling Techniques.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9iktAAKqIZX"
      },
      "source": [
        "# **Feature Transformation and Scaling Techniques.**\n",
        "\n",
        "Feature Scaling is a method used to normalize the range of independent variables or features of data. In data processing, it is also known as data normalization and is performed during the data preprocessing step.\n",
        "\n",
        "> [**Importance of Feature Scaling**](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html)\n",
        "\n",
        "> [**sklearn.preprocessing: Preprocessing and Normalization**](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)\n",
        "\n",
        "> [**Feature Scaling Techniques**](https://www.analyticsvidhya.com/blog/2020/07/types-of-feature-transformation-and-scaling/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "TbeMlD2YsxMv",
        "outputId": "039a36c9-4117-43a9-f7db-282332081e8e"
      },
      "source": [
        "# Import Library.\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load Dataset.\n",
        "data = pd.read_csv(\n",
        "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\",\n",
        "    header=None,\n",
        ")\n",
        "\n",
        "data.columns = [\n",
        "    \"Class Label\",\n",
        "    \"Alcohol\",\n",
        "    \"Malic Acid\",\n",
        "    \"Ash\",\n",
        "    \"Alkalinity of Ash\",\n",
        "    \"Magnesium\",\n",
        "    \"Total Phenols\",\n",
        "    \"Flavanoids\",\n",
        "    \"Nonflavanoid Phenols\",\n",
        "    \"Proanthocyanidins\",\n",
        "    \"Color Intensity\",\n",
        "    \"Hue\",\n",
        "    \"OD280/OD315 of Diluted Wines\",\n",
        "    \"Proline\",\n",
        "]\n",
        "\n",
        "data = data.iloc[:, 1:]\n",
        "data.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Alcohol  Malic Acid   Ash  Alkalinity of Ash  Magnesium  Total Phenols  \\\n",
              "0    14.23        1.71  2.43               15.6        127           2.80   \n",
              "1    13.20        1.78  2.14               11.2        100           2.65   \n",
              "2    13.16        2.36  2.67               18.6        101           2.80   \n",
              "3    14.37        1.95  2.50               16.8        113           3.85   \n",
              "4    13.24        2.59  2.87               21.0        118           2.80   \n",
              "\n",
              "   Flavanoids  Nonflavanoid Phenols  Proanthocyanidins  Color Intensity   Hue  \\\n",
              "0        3.06                  0.28               2.29             5.64  1.04   \n",
              "1        2.76                  0.26               1.28             4.38  1.05   \n",
              "2        3.24                  0.30               2.81             5.68  1.03   \n",
              "3        3.49                  0.24               2.18             7.80  0.86   \n",
              "4        2.69                  0.39               1.82             4.32  1.04   \n",
              "\n",
              "   OD280/OD315 of Diluted Wines  Proline  \n",
              "0                          3.92     1065  \n",
              "1                          3.40     1050  \n",
              "2                          3.17     1185  \n",
              "3                          3.45     1480  \n",
              "4                          2.93      735  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01dd953d-6f24-4e14-bc6a-bfc2b50add85\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Malic Acid</th>\n",
              "      <th>Ash</th>\n",
              "      <th>Alkalinity of Ash</th>\n",
              "      <th>Magnesium</th>\n",
              "      <th>Total Phenols</th>\n",
              "      <th>Flavanoids</th>\n",
              "      <th>Nonflavanoid Phenols</th>\n",
              "      <th>Proanthocyanidins</th>\n",
              "      <th>Color Intensity</th>\n",
              "      <th>Hue</th>\n",
              "      <th>OD280/OD315 of Diluted Wines</th>\n",
              "      <th>Proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01dd953d-6f24-4e14-bc6a-bfc2b50add85')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01dd953d-6f24-4e14-bc6a-bfc2b50add85 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01dd953d-6f24-4e14-bc6a-bfc2b50add85');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgSaFBpZumLm",
        "outputId": "3982704a-2cba-4a2d-f172-32219f6c1aa7"
      },
      "source": [
        "# Data Summary.\n",
        "data.info()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 178 entries, 0 to 177\n",
            "Data columns (total 13 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   Alcohol                       178 non-null    float64\n",
            " 1   Malic Acid                    178 non-null    float64\n",
            " 2   Ash                           178 non-null    float64\n",
            " 3   Alkalinity of Ash             178 non-null    float64\n",
            " 4   Magnesium                     178 non-null    int64  \n",
            " 5   Total Phenols                 178 non-null    float64\n",
            " 6   Flavanoids                    178 non-null    float64\n",
            " 7   Nonflavanoid Phenols          178 non-null    float64\n",
            " 8   Proanthocyanidins             178 non-null    float64\n",
            " 9   Color Intensity               178 non-null    float64\n",
            " 10  Hue                           178 non-null    float64\n",
            " 11  OD280/OD315 of Diluted Wines  178 non-null    float64\n",
            " 12  Proline                       178 non-null    int64  \n",
            "dtypes: float64(11), int64(2)\n",
            "memory usage: 18.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and test set.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test = train_test_split(data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "83ViHR4pBksF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cggASHTUrVrv"
      },
      "source": [
        "# **Normalization ($MinMax$ $Scaler$)**\n",
        "\n",
        "> [**sklearn.preprocessing.MinMaxScaler**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler)\n",
        "\n",
        "Transform features by scaling each feature to a given range. $MinMaxScaler$ estimator scales and translates each feature individually such that it is in the given range on the training set, i.e., between 0 and 1.\n",
        "\n",
        "> # **$X_{Scaled} = \\frac{X - X_{min}}{X_{max} - X_{min}}$**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZUBZK-LouH0",
        "outputId": "ed75d5d2-afa3-4e90-a577-d5c736c662ae"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X_train)\n",
        "print(X)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.87105263 0.16089613 0.71657754 ... 0.07317073 0.25274725 0.30102443]\n",
            " [0.39473684 0.94093686 0.68449198 ... 0.27642276 0.15384615 0.18676123]\n",
            " [0.35263158 0.03665988 0.39572193 ... 0.45528455 0.54945055 0.30102443]\n",
            " ...\n",
            " [0.88157895 0.19959267 0.54545455 ... 0.58536585 0.63369963 1.        ]\n",
            " [0.43684211 0.13034623 0.48128342 ... 0.3902439  0.28937729 0.17100079]\n",
            " [0.34473684 0.31771894 0.58823529 ... 0.2601626  0.77289377 0.12608353]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = scaler.transform(X_test)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "eE3JdAIWCAGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL45lkjxvkul"
      },
      "source": [
        "# **Standardization ($Standard$ $Scaler$)**\n",
        "\n",
        "> [**sklearn.preprocessing.StandardScaler**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)\n",
        "\n",
        "Standardize features by removing the mean (i.e., $mean = 0$) and scaling to unit variance. The standard score is calculated as:\n",
        "\n",
        "> # **$Z = \\frac{X - \\mu}{\\sigma}$**\n",
        "\n",
        "where $\\mu$ is the mean of the training samples and $\\sigma$ is the standard deviation of the training samples.\n",
        "\n",
        "Centering and Scaling happen independently on each feature by computing the relevant statistics on the samples in the training set. Both the mean and standard deviation are then stored to be used on later data using transform."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC2W7UMf0lVb",
        "outputId": "4f28c789-a07f-4186-916b-b8c46335bc74"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X_train)\n",
        "print(X)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.66529275 -0.60840587  1.21896194 ... -1.65632857 -0.87940904\n",
            "  -0.24860607]\n",
            " [-0.54952506  2.7515415   1.00331502 ... -0.58463272 -1.25462095\n",
            "  -0.72992237]\n",
            " [-0.74531007 -1.14354109 -0.93750727 ...  0.35845962  0.2462267\n",
            "  -0.24860607]\n",
            " ...\n",
            " [ 1.714239   -0.44172441  0.06884503 ...  1.04434496  0.56585166\n",
            "   2.69572196]\n",
            " [-0.35374006 -0.7399965  -0.36244882 ...  0.01551695 -0.74044166\n",
            "  -0.79631083]\n",
            " [-0.78201975  0.06709269  0.35637426 ... -0.67036839  1.09392769\n",
            "  -0.98551793]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = scaler.transform(X_test)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "yvDgiQvGCuc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kQYYYib1uE6"
      },
      "source": [
        "# **$MaxAbsScaler$**\n",
        "\n",
        "> [**sklearn.preprocessing.MaxAbsScaler**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler)\n",
        "\n",
        "Scale each feature by its maximum absolute value. That is, the $MaxAbs$ scaler takes the absolute maximum value of each column and divides each value in the column by the maximum value. This operation scales the data between the range $[-1, +1]$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJhCObF6BQZO",
        "outputId": "e9570364-dbee-433c-9be4-d4a39578f305"
      },
      "source": [
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "\n",
        "scaler = MaxAbsScaler()\n",
        "X = scaler.fit_transform(X_train)\n",
        "print(X)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.96695887 0.28965517 0.83591331 ... 0.33333333 0.49       0.42663219]\n",
            " [0.84490897 0.95       0.81733746 ... 0.47953216 0.4225     0.33290239]\n",
            " [0.83412003 0.18448276 0.6501548  ... 0.60818713 0.6925     0.42663219]\n",
            " ...\n",
            " [0.9696561  0.32241379 0.73684211 ... 0.70175439 0.75       1.        ]\n",
            " [0.85569791 0.2637931  0.6996904  ... 0.56140351 0.515      0.31997414]\n",
            " [0.8320971  0.42241379 0.76160991 ... 0.46783626 0.845      0.28312864]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = scaler.transform(X_test)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "M9e6sQaaC1Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1iRmQ8ECUYM"
      },
      "source": [
        "# **Robust Scaler**\n",
        "\n",
        "> [**sklearn.preprocessing.RobustScaler**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler)\n",
        "\n",
        "**Scale features using statistics that are robust to outliers.**\n",
        "\n",
        "In the previous feature scaling techniques, each method uses values like the mean, maximum and minimum values of the features. All these above feature scaling techniques are sensitive to outliers. If there are too many outliers in the data, then these outliers will influence the mean, the maximum value, or the minimum value. Thus, even if we scale the data using the above methods, we cannot guarantee a balanced dataset with a normal distribution.\n",
        "\n",
        "> # **$X_{Scaled} = \\frac{X - Q1}{Q3 - Q1}$**\n",
        "\n",
        "The Inter-Quartile Range $IQR$ is the difference between the first and third quartile of the variable. The Inter-Quartile Range can be defined as $IQR = Q3 - Q1$\n",
        "\n",
        "This Scaler removes the median and scales the data according to the quantile range (defaults to $IQR$: Inter-Quartile Range). The $IQR$ is the range between the $1^{st}$ quartile ($25^{th}$ quantile) and the $3^{rd}$ quartile ($75^{th}$ quantile).\n",
        "\n",
        "**The Robust Scaler is not sensitive to outliers.**\n",
        "\n",
        "1.   Robust Scaler removes the median from the data.\n",
        "2.   Robust Scaler scales the data by the Inter-Quartile Range ($IQR$)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Beuo36BMCgmk",
        "outputId": "42a4af8b-f9a3-45c2-9b84-9bddaf7f4538"
      },
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "scaler = RobustScaler()\n",
        "X = scaler.fit_transform(X_train)\n",
        "print(X)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.98884758 -0.12828947  1.03030303 ... -1.17037037 -0.61163227\n",
            "   0.        ]\n",
            " [-0.35687732  2.39144737  0.84848485 ... -0.42962963 -0.81425891\n",
            "  -0.33701336]\n",
            " [-0.47583643 -0.52960526 -0.78787879 ...  0.22222222 -0.00375235\n",
            "   0.        ]\n",
            " ...\n",
            " [ 1.01858736 -0.00328947  0.06060606 ...  0.6962963   0.16885553\n",
            "   2.0615921 ]\n",
            " [-0.23791822 -0.22697368 -0.3030303  ... -0.01481481 -0.53658537\n",
            "  -0.38349797]\n",
            " [-0.49814126  0.37828947  0.3030303  ... -0.48888889  0.45403377\n",
            "  -0.51597908]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = scaler.transform(X_test)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "JHejlz1VC_b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr5vHQbBNSMx"
      },
      "source": [
        "# **Quantile Transformer Scaler**\n",
        "\n",
        "> [**sklearn.preprocessing.QuantileTransformer**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html#sklearn.preprocessing.QuantileTransformer)\n",
        "\n",
        "**Transform features using quantiles information.**\n",
        "\n",
        "The Quantile Transformer Scaler converts the variable distribution to a normal distribution and scales it accordingly. Since it makes the variable normally distributed, it also deals with the outliers.\n",
        "\n",
        "This method transforms the features to follow a uniform or a normal distribution. Therefore for a given feature, this transformation tends to spread out the most frequent values. It also reduces the impact of (marginal) outliers, i.e., this is a robust preprocessing scheme. The transformation is applied to each feature independently.\n",
        "\n",
        "**A few points regarding the Quantile Transformer Scaler:**\n",
        "\n",
        "1.   It computes the cumulative distribution function of the variable.\n",
        "2.   It uses the cumulative distribution function to map the values to a normal distribution.\n",
        "3.   Maps the obtained values to the desired output distribution using the associated quantile function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKNQqA_jRS2P",
        "outputId": "e63dee29-15f6-49cf-b5cc-bdf497553008"
      },
      "source": [
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "scaler = QuantileTransformer()\n",
        "X = scaler.fit_transform(X_train)\n",
        "print(X)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.95744681 0.32978723 0.91134752 ... 0.04609929 0.26950355 0.4964539 ]\n",
            " [0.34042553 0.9858156  0.84397163 ... 0.29432624 0.15602837 0.27304965]\n",
            " [0.27659574 0.04964539 0.13120567 ... 0.60992908 0.4893617  0.4964539 ]\n",
            " ...\n",
            " [0.9751773  0.4929078  0.55319149 ... 0.84397163 0.64539007 1.        ]\n",
            " [0.38297872 0.21276596 0.31914894 ... 0.4893617  0.30141844 0.23404255]\n",
            " [0.25531915 0.64539007 0.67730496 ... 0.27304965 0.86879433 0.14893617]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = scaler.transform(X_test)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "vjD5nxaJDEoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km8Q4aAThI5F"
      },
      "source": [
        "# **Power Transformer Scaler**\n",
        "\n",
        "> [**sklearn.preprocessing.PowerTransformer**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer)\n",
        "\n",
        "Power transforms are a family of parametric, monotonic transformations applied to make data more Gaussian-like. This is useful for modeling issues related to heteroscedasticity (non-constant variance) or other situations where normality is desired.\n",
        "\n",
        "Currently, $PowerTransformer$ supports the **Box-Cox** transform and the **Yeo-Johnson** transform. The optimal parameter for stabilizing variance and minimizing skewness is estimated through maximum likelihood."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A48_IWs7hqAs",
        "outputId": "36cc3ff4-9aae-42cc-ae7f-61ae61cb0f52"
      },
      "source": [
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "scaler = PowerTransformer(method=\"yeo-johnson\")\n",
        "\"\"\"\n",
        "parameters: method = \"box-cox\" or \"yeo-johnson\"\n",
        "\"\"\"\n",
        "X = scaler.fit_transform(X_train)\n",
        "print(X)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.64748053 -0.51062513  1.22815618 ... -1.69276625 -0.90739595\n",
            "  -0.04293367]\n",
            " [-0.54211128  1.88663311  1.00528748 ... -0.5712274  -1.24094609\n",
            "  -0.67033838]\n",
            " [-0.74051811 -1.66387873 -0.94115643 ...  0.37491807  0.19605565\n",
            "  -0.04293367]\n",
            " ...\n",
            " [ 1.69479997 -0.24810801  0.05450034 ...  1.04231668  0.53592188\n",
            "   1.98256983]\n",
            " [-0.34453499 -0.74457239 -0.37588826 ...  0.03488343 -0.77936539\n",
            "  -0.77214116]\n",
            " [-0.77781294  0.38047054  0.34441975 ... -0.65902822  1.12177325\n",
            "  -1.08943917]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = scaler.transform(X_test)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "UYaz5yylDV5d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}